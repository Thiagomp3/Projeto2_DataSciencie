{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Thiago Maitan Pegorer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Raphael Jacob Butori**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador automático de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autenticando no Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @pegorer_thi\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Samsung'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if msg.full_text.lower()[0] != 'r' and msg.full_text.lower()[1] != 't':\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alerta de oferta: samsung galaxy a30 a partir ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apesar de amar a samsung. vi hoje que a #xiaom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odeio samsung. pqppp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@hearthstoneness @cissamagazine na loja tbm né...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tenho que comprar um celular novo mas 0 vontad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificador\n",
       "0  alerta de oferta: samsung galaxy a30 a partir ...              0\n",
       "1  apesar de amar a samsung. vi hoje que a #xiaom...              0\n",
       "2                               odeio samsung. pqppp              1\n",
       "3  @hearthstoneness @cissamagazine na loja tbm né...              0\n",
       "4  tenho que comprar um celular novo mas 0 vontad...              1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw=pd.read_excel(\"Samsung.xlsx\")\n",
    "tw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando pontuação do excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alerta de oferta samsung galaxy a30 a partir d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apesar de amar a samsung vi hoje que a xiaomi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odeio samsung pqppp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearthstoneness cissamagazine na loja tbm né n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tenho que comprar um celular novo mas 0 vontad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificador\n",
       "0  alerta de oferta samsung galaxy a30 a partir d...              0\n",
       "1  apesar de amar a samsung vi hoje que a xiaomi ...              0\n",
       "2                                odeio samsung pqppp              1\n",
       "3  hearthstoneness cissamagazine na loja tbm né n...              0\n",
       "4  tenho que comprar um celular novo mas 0 vontad...              1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#string punctuation contem todas as pontuacoes ja\n",
    "pontuacao = string.punctuation\n",
    "\n",
    "ponto = [\"\\n\", \"\\t\"]\n",
    "\n",
    "#criando uma lista\n",
    "limpeza = []\n",
    "\n",
    "for tweet in tw[\"Treinamento\"]:\n",
    "    x = ''\n",
    "    for palavra in tweet:\n",
    "        if palavra in ponto:\n",
    "            x += \" \"\n",
    "        elif palavra not in pontuacao:\n",
    "            x += palavra\n",
    "    limpeza.append(x)\n",
    "\n",
    "tw_sam =  pd.DataFrame()\n",
    "tw_sam['Treinamento'] = limpeza\n",
    "tw_sam['Classificador'] = tw['Classificador']\n",
    "\n",
    "tw_sam.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante=tw_sam.loc[tw_sam.Classificador==1]\n",
    "#print(len(relevante))\n",
    "irrelevante=tw_sam.loc[tw_sam.Classificador==0]\n",
    "#print(len(irrelevante))\n",
    "j=relevante.Treinamento\n",
    "k=irrelevante.Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elaboração das funções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anexando os tweets em uma lista\n",
    "def split(relevanciaT):\n",
    "    listapalavras=[]\n",
    "    for e in relevanciaT:\n",
    "        tweet=e.split()\n",
    "        for palavra in tweet:\n",
    "            listapalavras.append(palavra)\n",
    "    return listapalavras\n",
    "#print(split(j))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequencia palavras\n",
    "def FP(tweetsplit):\n",
    "    y={}\n",
    "    for x in tweetsplit:\n",
    "        if x not in y:\n",
    "            y[x]=2\n",
    "        if x in y:\n",
    "            y[x]+=1\n",
    "    return y\n",
    "#print(FP(listarelev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aqui foi utilizada a condicao inicial 2 para aplicacao do smoothing de laplace, a parte referente as palavras nao identificadas sera aplicada somente no classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRTW(y,relevancia):\n",
    "    frelattw={}\n",
    "    for x,z in y.items():\n",
    "        b=z/len(relevancia)\n",
    "        frelattw[x]=b\n",
    "    return frelattw\n",
    "#print(FRTW(y))\n",
    "\n",
    "#frequencia relativa por tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcula a frequencia relativa das palavras com relacao ao todo das palavras\n",
    "def FRP(y,lpal):\n",
    "    frelatpal={}\n",
    "    for x,z in y.items():\n",
    "        b=z/(len(lpal)+len(y))\n",
    "        frelatpal[x]=b\n",
    "    return frelatpal\n",
    "#print(FRP(y,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação das variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsplitado=split(j)\n",
    "Rcontagem=FP(Rsplitado)\n",
    "Rfrtw=FRTW(Rcontagem,relevante)#frequencia relativa das palavras em tweets relevantes\n",
    "Rfrp=FRP(Rcontagem,Rsplitado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Irrelevante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Isplitado=split(k)\n",
    "Icontagem=FP(Isplitado)\n",
    "Ifrtw=FRTW(Icontagem,irrelevante)#frequencia relativa das palavras em tweets irrelevantes\n",
    "Ifrp=FRP(Icontagem,Isplitado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação FRTW (Frequencia Relativa à Tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de a principio aparentar ser mais viável utilizar como referência para o classificador a frequência por tweet da palavra ao invés de sua frequência relativa com relação ao todo, nos deparamos com problemas com relação à influência que artigos estavam tendo no resultado final , uma vez que os mesmos estavam presentes na maioria dos relevantes, assim o impacto que os mesmos tinham no tweet ser relevante ou não acabava sendo imenso, com isso partimos para a opção seguinte, o FRP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet='porra meu samsung nao para de travar pqp odeio essa bosta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificadorFRTW(tweet):\n",
    "    pontuacao = string.punctuation\n",
    "\n",
    "    ponto = [\"\\n\", \"\\t\"]\n",
    "\n",
    "    x = ''\n",
    "    for palavra in tweet:\n",
    "        if palavra in ponto:\n",
    "            x += \" \"\n",
    "        elif palavra not in pontuacao:\n",
    "            x += palavra\n",
    "    twsplit=x.split()\n",
    "    #print (x) # teste de espaço excessivo\n",
    "    #print(twsplit) # teste de espaço excessivo\n",
    "    total=0\n",
    "    irrelevancia=1\n",
    "    relevancia=1\n",
    "    nao_identificadasR=1\n",
    "    nao_identificadasI=1\n",
    "    resultado=0\n",
    "    for x in twsplit:\n",
    "        if x in Rfrtw:\n",
    "            relevancia*=Rfrtw[x]\n",
    "        elif x not in Ifrp:\n",
    "            nao_identificadasR*=1/len(Rfrp)+len(Ifrp)\n",
    "        print(x)\n",
    "        print ('relevancia:{0}'.format(relevancia))\n",
    "    for x in twsplit:\n",
    "        if x in Ifrtw:\n",
    "            irrelevancia*=Ifrtw[x]\n",
    "        elif x not in Rfrp:\n",
    "            nao_identificadasI*=1/len(Ifrp)+len(Isplitado)\n",
    "        print(x)\n",
    "        print ('irrelevancia:{0}'.format(irrelevancia))\n",
    "    total=((relevancia)*nao_identificadasR)-((irrelevancia)*nao_identificadasI)\n",
    "    print('total:{0}'.format(total))\n",
    "    if total>0:\n",
    "        resultado='relevante'\n",
    "    else:\n",
    "        resultado='irrelevante'\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porra\n",
      "relevancia:0.024\n",
      "meu\n",
      "relevancia:0.005952\n",
      "samsung\n",
      "relevancia:0.006332928\n",
      "nao\n",
      "relevancia:0.000303980544\n",
      "para\n",
      "relevancia:2.6750287872e-05\n",
      "de\n",
      "relevancia:1.284013817856e-05\n",
      "travar\n",
      "relevancia:2.0544221085696e-07\n",
      "pqp\n",
      "relevancia:2.0544221085696e-07\n",
      "odeio\n",
      "relevancia:6.57415074742272e-09\n",
      "essa\n",
      "relevancia:4.2074564783505413e-10\n",
      "bosta\n",
      "relevancia:1.3463860730721732e-11\n",
      "porra\n",
      "irrelevancia:0.022857142857142857\n",
      "meu\n",
      "irrelevancia:0.003004081632653061\n",
      "samsung\n",
      "irrelevancia:0.003072746355685131\n",
      "nao\n",
      "irrelevancia:7.023420241566014e-05\n",
      "para\n",
      "irrelevancia:4.816059594216696e-06\n",
      "de\n",
      "irrelevancia:1.7337814539180105e-06\n",
      "travar\n",
      "irrelevancia:1.7337814539180105e-06\n",
      "pqp\n",
      "irrelevancia:3.962929037526881e-08\n",
      "odeio\n",
      "irrelevancia:3.962929037526881e-08\n",
      "essa\n",
      "irrelevancia:1.1322654392933946e-09\n",
      "bosta\n",
      "irrelevancia:1.1322654392933946e-09\n",
      "total:-1.1188015785626729e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'irrelevante'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassificadorFRTW(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador FRP (Frequencia Relativa à Palavras)(produto final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificadorFRP(tweet):\n",
    "    pontuacao = string.punctuation\n",
    "\n",
    "    ponto = [\"\\n\", \"\\t\"]\n",
    "\n",
    "    x = ''\n",
    "    for palavra in tweet:\n",
    "        if palavra in ponto:\n",
    "            x += \" \"\n",
    "        elif palavra not in pontuacao:\n",
    "            x += palavra\n",
    "    twsplit=x.split()\n",
    "    print (x) # teste de espaço excessivo\n",
    "    print(twsplit) # teste de espaço excessivo\n",
    "    total=0\n",
    "    irrelevancia=1\n",
    "    relevancia=1\n",
    "    resultado=0\n",
    "    nao_identificadasR=1\n",
    "    nao_identificadasI=1\n",
    "    for x in twsplit:\n",
    "        if x in Rfrp:\n",
    "            relevancia*=Rfrp[x]\n",
    "            print(x)\n",
    "            print ('relevancia:{0}'.format(relevancia))\n",
    "        else:\n",
    "            nao_identificadasR*=1/(len(Rfrp)+len(Rsplitado))\n",
    "    for x in twsplit:\n",
    "        if x in Ifrp:\n",
    "            irrelevancia*=Ifrp[x]\n",
    "            print(x)\n",
    "            print ('irrelevancia:{0}'.format(irrelevancia))\n",
    "        else:\n",
    "            nao_identificadasI*=1/(len(Ifrp)+len(Isplitado))\n",
    "\n",
    "\n",
    "    total=((relevancia)*nao_identificadasR)-((irrelevancia)*nao_identificadasI)\n",
    "    \n",
    "    print('total:{0}'.format(total))\n",
    "    if total>0:\n",
    "        resultado='relevante'\n",
    "    else:\n",
    "        resultado='irrelevante'\n",
    "    return resultado\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porra meu samsung nao para de travar pqp odeio essa bosta\n",
      "['porra', 'meu', 'samsung', 'nao', 'para', 'de', 'travar', 'pqp', 'odeio', 'essa', 'bosta']\n",
      "porra\n",
      "relevancia:0.0009609224855861628\n",
      "meu\n",
      "relevancia:9.541510907485922e-06\n",
      "samsung\n",
      "relevancia:4.0647692206778585e-07\n",
      "nao\n",
      "relevancia:7.811856285735795e-10\n",
      "para\n",
      "relevancia:2.7524157316814137e-12\n",
      "de\n",
      "relevancia:5.2897163325075216e-14\n",
      "travar\n",
      "relevancia:3.388671577519232e-17\n",
      "odeio\n",
      "relevancia:4.3416676201399506e-20\n",
      "essa\n",
      "relevancia:1.1125349443023575e-22\n",
      "bosta\n",
      "relevancia:1.4254131253073125e-25\n",
      "porra\n",
      "irrelevancia:0.0013550135501355014\n",
      "meu\n",
      "irrelevancia:1.0557354896042185e-05\n",
      "samsung\n",
      "irrelevancia:6.401648124632625e-07\n",
      "nao\n",
      "irrelevancia:8.674319952076728e-10\n",
      "para\n",
      "irrelevancia:3.5261463219824098e-12\n",
      "de\n",
      "irrelevancia:7.525312272523436e-14\n",
      "pqp\n",
      "irrelevancia:1.0196900098270239e-16\n",
      "essa\n",
      "irrelevancia:1.727117225316775e-19\n",
      "total:4.33441015944792e-29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'relevante'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassificadorFRP(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-dfc033836011>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-dfc033836011>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    a=classificador frp (x)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for x in teste:\n",
    "    a=classificador frp (x)\n",
    "    if a=='irrelevante':\n",
    "        sam[classificado]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progresso possível"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além da óbvia melhoria de precisão aumentando o grupo de controle feito manualmente,e a divisão em subcategorias sobre o tipo de feedback recebido, não apenas se consiste em um feedback de usuário ou não(o que foi considerado como relevante neste projeto), uma possível melhoria seria a eliminação de artigos como grande influência no classificador.Tratando de um grupo de controle pequeno quando comparado à escala empresarial, a presença de artigos pessoais em um texto faz com que este tenda fortemente para o lado relevante, uma vez que os textos considerados relevantes vem de usuários expressando o feedback, um problema surge quando companhias fazem anúncios com o intúito de aproximar o usuário, utilizando artigos informais e confundindo o classificador, com uma base de dados maior como treinamento este problema caminharia para uma solução automática uma vez que estes anúncios seriam levados em conta, porém tratando de uma escala menor talvez fosse interessante abanar a influência deles sob o programa, isso seria feito criando uma lista com os artigos mais frequentemente utilizados em anúncios (que poderia ser criada cruzando uma lista de artigos com um programa que examina a frequencia dos mesmos em um DF de anuncios) ou por inserção manual de uma parcela maior de anúncios desse caráter no dataframe inicial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Por que não usar o Treinamento para validação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utilização do grupo de treinamento também como grupo de validação não corresponde à como o classificador atuaria numa situação com um novo tweet , utilizando-o no grupo de treinamento todas as palavras da frase teriam um valor atribuído a elas , uma situação utópica, e o resultado esperado deveria ser uma precisão também muito acima do que como o classificador realmente atuaria em ação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em qualquer situação onde é possivel atribuir uma condição de sucesso ou não sucesso à uma variável , não necessáriamente em um padrão visível e não necessáriamente apenas uma variável , é possivel aplicar o naive bayes em uma série de variáveis atreladas à um resultado , a probabilidade de sucesso atrelada à cada variável disposta em uma situação a ser prevista resultará em um produto que permite fazer uma previsão baseada em comportamento prévio. como exemplo pode se usar qualquer situação: -> aninha foi x dia ao parque , estava sol e ela estava de chinelo -> aninha não foi ao parque no dia z , estava chuva e ela estava de chinelo (...) e assim vai no final conseguindo atribuir valores de probabilidade de sucesso á cada uma das variáveis em questão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
